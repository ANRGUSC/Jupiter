#############################################################################################
                                   result for tpheft
#############################################################################################
==============================================
               print task info
==============================================
task_number            task_uprank
(0, '              ', 8965.876591118064)
(1, '              ', 4150.862973294417)
(2, '              ', 3810.2930382946743)
(3, '              ', 663)
==============================================
               print processor info
==============================================
processor_number     task_number     start_time     end_time
('     ', 2, '      ', 0, '    ', 0, '    ', 2084)
('     ', 3, '      ', 1, '    ', 0, '    ', 577)
('     ', 5, '      ', 3, '    ', 0, '    ', 714)
('     ', 14, '      ', 2, '    ', 0, '    ', 452)
==============================================
               print link info
==============================================
link_name    start_task_num   end_task_num   start_time   end_time
('2_3', '      ', 0, '      ', 1, '       ', 0, '      ', 251.74367998171522)
('2_14', '      ', 0, '      ', 2, '       ', 0, '      ', 5722.45581935868)
('3_5', '      ', 1, '      ', 3, '       ', 0, '      ', 221.8870010988937)
('14_5', '      ', 2, '      ', 3, '       ', 0, '      ', 5777.531977330065)

-------------------------------
current system bottleneck: 14_5
task ids to dup, task ids to recv, files_to_dst, files_from_src
[2]
[3]
[36864]
{2: [32768]}
procid to max time
{0: 426, 1: 266, 4: 391, 6: 525, 7: 576, 8: 3053.2086564571864, 9: 2888.0096112789074, 10: 2910.1394428331528, 11: 2860.453935087241, 12: 5703.918194980515, 13: 5655.741782522038}
chosen node id, min btnk, task ids to dup, tak ids to recv, parent tasks, files to dest, files from src
(1, 266, [2], [3], [0], [36864], {2: [32768]})
-------------------------------
Conclusion for this round of duplication: chose new node and duplicate following tasks on it
(1, [2])
task numbers: ori to dup, dup to ori
{2: 4}
{4: 2}
original data matrix
[[-1, 32768, 32768, -1], [-1, -1, -1, 28672], [-1, -1, -1, 36864], [-1, -1, -1, -1]]
updated data transfer matrix with task duplication
[[-1, 32768, 32768, -1, 32768], [-1, -1, -1, 28672, -1], [-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1], [-1, -1, -1, 36864, -1]]
updated task names with dupicated tasks
['task0', 'task1', 'task2', 'task3', 'task2-dup']
new_link to dst
1_5
(4, ' ', 3, ' ', 0, ' ', 199.35155740616)
new_link from parents
2_1
(0, ' ', 4, ' ', 0, ' ', 241.2145945009383)



Output of HEFT scheduler
#############################################################################################
                                 result for rand + dup
#############################################################################################
==============================================
               print task info
==============================================
task_number            task_uprank
(0, '              ', 8965.876591118064)
(1, '              ', 4150.862973294417)
(2, '              ', 3810.2930382946743)
(3, '              ', 663)
(4, '              ', 3810.2930382946743)
==============================================
               print processor info
==============================================
processor_number     task_number     start_time     end_time
('     ', 1, '      ', 4, '    ', 0, '    ', 266)
('     ', 2, '      ', 0, '    ', 0, '    ', 2084)
('     ', 3, '      ', 1, '    ', 0, '    ', 577)
('     ', 5, '      ', 3, '    ', 0, '    ', 714)
('     ', 14, '      ', 2, '    ', 0, '    ', 452)
==============================================
               print link info
==============================================
link_name    start_task_num   end_task_num   start_time   end_time
('1_5', '      ', 4, '      ', 3, '       ', 0, '      ', 199.35155740616)
('2_1', '      ', 0, '      ', 4, '       ', 0, '      ', 241.2145945009383)
('2_3', '      ', 0, '      ', 1, '       ', 0, '      ', 251.74367998171522)
('2_14', '      ', 0, '      ', 2, '       ', 0, '      ', 5722.45581935868)
('3_5', '      ', 1, '      ', 3, '       ', 0, '      ', 221.8870010988937)
('14_5', '      ', 2, '      ', 3, '       ', 0, '      ', 5777.531977330065)

assignments

{'task0': 'node3', 'task1': 'node4', 'task2': 'node15', 'task3': 'node6', 'UPDATED_DAG_FILE_WITH_DUPICATION': '5\ntask0 1 true task1 task2 task2-dup\ntask1 1 true task3\ntask2 1 true\ntask3 2 true home\ntask2-dup 1 true task3\n', 'task2-dup': 'node2'}
Assign random master and slaves
 * Serving Flask app "master" (lazy loading)
 * Environment: production
   WARNING: This is a development server. Do not use it in a production deployment.
   Use a production WSGI server instead.
 * Debug mode: off
 * Running on http://0.0.0.0:8888/ (Press CTRL+C to quit)
('Recieved request for current mapping. Current mappings done:', 6)
{'task0': 'node3', 'task1': 'node4', 'task2': 'node15', 'task3': 'node6', 'UPDATED_DAG_FILE_WITH_DUPICATION': '5\ntask0 1 true task1 task2 task2-dup\ntask1 1 true task3\ntask2 1 true\ntask3 2 true home\ntask2-dup 1 true task3\n', 'task2-dup': 'node2'}
10.244.0.1 - - [10/Sep/2020 06:31:41] "GET / HTTP/1.1" 200 -

